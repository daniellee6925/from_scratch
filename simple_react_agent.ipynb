{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ca055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e7465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as parameter-efficient language models, have revolutionized the field of natural language processing (NLP) by enabling fast and accurate language understanding and generation. Here are the key imports of fast language models:\n",
      "\n",
      "1. **Speed and Scalability**: Fast language models can process text much faster than traditional language models, making them suitable for real-time applications, such as chatbots, virtual assistants, and language translation.\n",
      "2. **Improved Accuracy**: Despite their speed, fast language models often maintain or even surpass the accuracy of traditional language models, thanks to advances in quantization, pruning, and knowledge distillation techniques.\n",
      "3. **Resource Efficiency**: Fast language models require significantly fewer computational resources, memory, and energy than traditional language models, making them more suitable for deployment on resource-constrained devices, such as smartphones or embedded systems.\n",
      "4. **Flexibility**: Fast language models can be fine-tuned for specific tasks and domains, allowing developers to adapt them to a wide range of applications, from language translation and text summarization to sentiment analysis and question answering.\n",
      "5. **Enabling New Use Cases**: Fast language models have opened up new possibilities for applications that require real-time language processing, such as:\n",
      "\t* Conversational interfaces: fast language models can enable chatbots and virtual assistants to understand and respond to user queries in real-time.\n",
      "\t* Language translation: fast language models can translate text in real-time, enabling applications like Google Translate, for example.\n",
      "\t* Real-time text summarization: fast language models can summarize lengthy texts into shorter, more digestible formats, ideal for news and social media applications.\n",
      "6. **Advancements in Multimodal Processing**: Fast language models have enabled researchers to explore multimodal processing, where language models are combined with computer vision and audio processing capabilities to analyze and understand multimedia data, such as videos and images.\n",
      "7. **Explainability and Interpretability**: Fast language models often provide insights into the decision-making process, allowing developers to understand why the model made a particular prediction or recommendation.\n",
      "8. **Open-Source and Community-Built**: Many fast language models are open-source, fostering a community-driven development process that accelerates research, innovation, and deployment.\n",
      "9. **Enabling Edge AI**: Fast language models can be deployed on edge devices, enabling AI-powered language processing at the edge, closer to the user, reducing latency and improving responsiveness.\n",
      "10. **Long-Term Impact**: The development of fast language models is expected to have a long-term impact on the field of NLP, paving the way for further advancements in language processing, multimodal intelligence, and human-computer interaction.\n",
      "\n",
      "In summary, fast language models have revolutionized the field of NLP by providing a balance between speed, accuracy, and resource efficiency, enabling a wide range of applications, and advancing our understanding of language and multimodal intelligence.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key = os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the import of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model =\"llama3-70b-8192\"\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e723f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, client, system):\n",
    "        self.client = client\n",
    "        self.system = system\n",
    "        self.messages = [] # lsit of messages to include in memory\n",
    "        \n",
    "        if self.system is not None:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": self.system})\n",
    "          \n",
    "    def  __call__(self, message=\"\"):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "            \n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "    \n",
    "    def execute(self):\n",
    "        completion = client.chat.completions.create(\n",
    "            messages = self.messages,\n",
    "            model =\"llama3-70b-8192\"\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7824ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    match planet.lower():\n",
    "        case \"earth\":\n",
    "            return 5.972e24\n",
    "        case \"jupiter\":\n",
    "            return 1.898e27\n",
    "        case \"mars\":\n",
    "            return 6.39e23\n",
    "        case \"mercury\":\n",
    "            return 3.285e23\n",
    "        case \"neptune\":\n",
    "            return 1.024e26\n",
    "        case \"saturn\":\n",
    "            return 5.683e26\n",
    "        case \"uranus\":\n",
    "            return 8.681e25\n",
    "        case \"venus\":\n",
    "            return 4.867e24\n",
    "        case _:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "235615e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "neil_tyson = Agent(client, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d6a2bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: I need to find the mass of Earth\n"
     ]
    }
   ],
   "source": [
    "result = neil_tyson(\"What is the mass of the earth times 5?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f87c6d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You run in a loop of Thought, Action, PAUSE, Observation.\\nAt the end of the loop you output an Answer\\nUse Thought to describe your thoughts about the question you have been asked.\\nUse Action to run one of the actions available to you - then return PAUSE.\\nObservation will be the result of running those actions.\\n\\nYour available actions are:\\n\\ncalculate:\\ne.g. calculate: 4 * 7 / 3\\nRuns a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\\n\\nget_planet_mass:\\ne.g. get_planet_mass: Earth\\nreturns weight of the planet in kg\\n\\nExample session:\\n\\nQuestion: What is the mass of Earth times 2?\\nThought: I need to find the mass of Earth\\nAction: get_planet_mass: Earth\\nPAUSE \\n\\nYou will be called again with this:\\n\\nObservation: 5.972e24\\n\\nThought: I need to multiply this by 2\\nAction: calculate: 5.972e24 * 2\\nPAUSE\\n\\nYou will be called again with this: \\n\\nObservation: 1,1944×10e25\\n\\nIf you have the answer, output it as the Answer.\\n\\nAnswer: The mass of Earth times 2 is 1,1944×10e25.\\n\\nNow it's your turn:\"},\n",
       " {'role': 'user', 'content': 'What is the mass of the earth times 5?'},\n",
       " {'role': 'assistant', 'content': 'Thought: I need to find the mass of Earth'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neil_tyson.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6e658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
